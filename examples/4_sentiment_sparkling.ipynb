{"nbformat_minor": 1, "cells": [{"source": "### Let's first configure the Spark cluster\nAdd the jars for H2O sparkling water and the spark-csv. Also change the driver Memory to the size of the VM of the clusters.\n<br><b>Make sure that you are adding the right Sparkling Water version and setting the driver memory to match the RAM of the VM sizes selected on cluster creation </b>", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%configure -f\n{\n    \"conf\":{\n        \"spark.jars.packages\":\"ai.h2o:sparkling-water-core_2.10:1.6.8,com.databricks:spark-csv_2.10:1.5.0\"\n    },\n    \"driverMemory\":\"8G\"\n}", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Here we add the pySpark egg file from the downloaded H2O Sparkling water distribution.\n<br><b> Make sure that file name of the egg file below matches the downloaded distribution of Sparkling Water</b>", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "sc.addPyFile('wasb:///HdiNotebooks/H2O-Sparkling-Water/py/dist/h2o_pysparkling_1.6-1.6.8-py2.7.egg')\nimport os\nos.environ[\"PYTHON_EGG_CACHE\"] = \"~/\"", "outputs": [], "metadata": {"collapsed": false}}, {"source": "# Sentiment Analysis with PySparkling\nThe Amazon Fine Food Reviews dataset consists of 568,454 food reviews Amazon users left up to October 2012.\n\n> This data was originally published on SNAP as part of the paper: J. McAuley and J. Leskovec. _From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews_. WWW, 2013.", "cell_type": "markdown", "metadata": {}}, {"source": "## Prepare environment", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "import pyspark\nimport pysparkling, h2o\n\nh2o_context = pysparkling.H2OContext.getOrCreate(sc)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Load data into H2OFrame\n\n** Please change the variable `AMAZON_DATASET` to your environment specific location. **", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# This is just helper function returning the path to data files within sparkling-water project directories\ndef _locate(example_name): \n    return \"wasb:///HdiNotebooks/H2O-Sparkling-Water/examples/\" + example_name \n\nAMAZON_DATASET = 'Reviews.csv'\n\n# Add files to Spark Cluster\n\nsc.addFile(_locate(AMAZON_DATASET))", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "# And import them into H2O\nfrom pyspark import SparkFiles\n\n# Since we have already loaded files into spark, we have to use h2o.upload_file instead of \n# h2o.import_file since h2o.import_file expects cluster-relative path (ie. the file on this\n# path can be accessed from all the machines on the cluster) but SparkFiles.get(..) already\n# give us relative path to the file on a current node which h2o.upload_file can handle ( it\n# uploads file located on current node and distributes it to the H2O cluster)\n\nreviews_hf = h2o.upload_file(SparkFiles.get(AMAZON_DATASET))\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "reviews_hf.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Data munge data with H2O API", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "### Remove columns", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "selected_columns = [ \"Score\", \"Time\", \"Summary\", \"HelpfulnessNumerator\", \"HelpfulnessDenominator\" ]\nreviews_hf = reviews_hf[selected_columns]", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "reviews_hf.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Refine `Time` Column into Year/Month/Day/DayOfWeek/Hour columns\nIn this case the `Time` column contains number of seconds from epoch. We translate it into several new columns to help algorithms to pick right pattern.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "# Set time zone to UTC for date manipulation\nh2o.set_timezone(\"Etc/UTC\")", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "def refine_time_column(data_hf, column_name):\n    data_hf[column_name] = data_hf[column_name] * 1000 # Transformation to microsecond since required by H2O API\n    data_hf[\"Day\"] = data_hf[column_name].day()\n    data_hf[\"Month\"] = data_hf[column_name].month()\n    data_hf[\"Year\"] = data_hf[column_name].year()\n    data_hf[\"DayOfWeek\"] = data_hf[column_name].dayOfWeek()\n    data_hf[\"Hour\"] = data_hf[column_name].hour()\n    \nrefine_time_column(reviews_hf, \"Time\")\nreviews_hf.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Data Munge with Spark API\nWe can combine H2O data munging capabilities with Spark API\n\n### Publish H2O Frame as Spark DataFrame\n\nThe created H2OContext exposes the method `as_spark_frame` which publishes an H2OFrame as Spark DataFrame.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "reviews_df = h2o_context.as_spark_frame(reviews_hf)\nreviews_df.show()\n", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "#reviews_df.saveAsTable(\"reviewstable\")\nsqlContext.registerDataFrameAsTable(reviews_df, \"reviewstable\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql \nshow tables", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Spark DataFrame API\n\nFrom this point we can run any Spark data munging operations including SQL.\nWe can still publish the result as H2OFrame.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "avgScorePerYear = reviews_df.groupBy(\"Year\").agg({\"Score\" : \"avg\", \"*\": \"count\"}).orderBy(\"Year\")\navgScorePerYear.show()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "sqlContext.registerDataFrameAsTable(avgScorePerYear, \"avgscoretable\")", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Now we can query the hive table and output the results on a pandas dataframe (using the -o option)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%sql -q -n 500 -o query1\nselect * from avgscoretable", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### visualize the results directly in Python Notebook...", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%local\n%matplotlib inline\n\nquery1.plot.bar(x=\"Year\", y = \"count(1)\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Prepare data for modeling\nThe idea is to model sentiment based on `Score` of review, `Summary` and time when the review was performed. In this case we skip all neutral reviews, but focus on positive/negative scores.\n\nSteps:\n\n  1. Select columns Score, Month, Day, DayOfWeek, Summary\n  2. Define UDF to transform score (0..5) to binary positive/negative\n  3. Use TF-IDF to vectorize summary column\n\n#### Transform the `Score` column into binary feature\n\nThe score contains value (0, 5), however we are just interested in binary value - positive/negative review. We ignore neutral reviews.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark.sql.types import *\nfrom pyspark.sql.functions import UserDefinedFunction\n\ndef to_binary_score(col):\n    if col < 3:\n        return \"negative\"\n    else:\n        return \"positive\"\nudf_to_binary_score = UserDefinedFunction(to_binary_score, StringType())", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "reviews_df = reviews_df.withColumn(\"Score\", udf_to_binary_score(\"Score\"))\nreviews_df.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Transforming textual data into numeric representation\n\n#### Tokenization", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark.ml.feature import *\n\ntokenizer = Tokenizer(inputCol=\"Summary\", outputCol=\"tokens\")", "outputs": [], "metadata": {"collapsed": true}}, {"source": "#### Transform tokens into numeric representation\n\nWe use Spark `HashingTF` to represent tokens as numeric features.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "hashingTF = HashingTF()\nhashingTF.setInputCol(\"tokens\").setOutputCol(\"tf-features\").setNumFeatures(1024)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Build IDF (Inverse Document Frequency) model\nThe model scales a token frequency based on its occurence in a document and full set of documents.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "idf = IDF()\nidf.setInputCol(\"tf-features\")\nidf.setOutputCol(\"idf-features\")", "outputs": [], "metadata": {"collapsed": false}}, {"source": "#### Compose individual transformation into a Spark pipeline", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages = [tokenizer, hashingTF, idf])\npipelineModel = pipeline.fit(reviews_df)", "outputs": [], "metadata": {"collapsed": true}}, {"source": "#### And transform input data", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "final_reviews_df = pipelineModel.transform(reviews_df)\n#final_reviews_df.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Back to H2O Frame (materialization)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "final_columns = [\"Score\", \"HelpfulnessNumerator\", \"HelpfulnessDenominator\", \"Day\", \"Month\", \"Year\", \"DayOfWeek\", \"idf-features\"]\nfinal_reviews_hf = h2o_context.as_h2o_frame(final_reviews_df.select(final_columns), \"final_reviews_hf\")\nfinal_reviews_hf.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Score and DayOfWeek columns needs to be a factor", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "final_reviews_hf[\"Score\"] = final_reviews_hf[\"Score\"].asfactor()\nfinal_reviews_hf[\"DayOfWeek\"] = final_reviews_hf[\"DayOfWeek\"].asfactor()", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### Prepare training and validation dataset for modeling", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "splits = final_reviews_hf.split_frame(ratios=[0.75], destination_frames=[\"train\", \"valid\"], seed=42)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "train_hf = splits[0]\nvalid_hf = splits[1]\n#train_hf.show()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### Memory Cleanup", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "final_reviews_hf = None\nreviews_hf = None", "outputs": [], "metadata": {"collapsed": true}}, {"source": "#### List available data", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "h2o.ls()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Model training\n\n### Random grid search with explicit stopping criterions\n", "cell_type": "markdown", "metadata": {}}, {"source": "#### Define a hyper space to explore\n\n> Please feel free to play with parameters, see documentation in [H2O Python Documentation](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#module-h2o.grid.grid_search).", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "from h2o.grid.grid_search import H2OGridSearch\nfrom h2o.estimators.deeplearning import H2ODeepLearningEstimator\n\nhyper_params = {'activation' : [\"Rectifier\", \"TanhWithDropout\"], \n                'hidden' : [ [2,2], [10,10]],\n                'epochs' : [ 1, 2, 5]\n               }", "outputs": [], "metadata": {"collapsed": true}}, {"source": "#### Define stoping criterions\n\n> Modify based on your demands and requirements (time v. accuracy bound search)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "search_criteria = {'strategy' : 'RandomDiscrete',\n                   'max_runtime_secs': 120,\n                   'stopping_rounds' : 3,\n                   'stopping_metric' : 'AUC', # AUTO, mse, logloss\n                   'stopping_tolerance': 1e-2\n                   }", "outputs": [], "metadata": {"collapsed": true}}, {"source": "#### Launch Random Hyper Search\n\n> For more details look into [H2O Deep Learning documentation](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html#h2odeeplearningestimator)", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "models_grid = H2OGridSearch(H2ODeepLearningEstimator, hyper_params=hyper_params, search_criteria=search_criteria)\nmodels_grid.train(x = train_hf.col_names, y = \"Score\", \\\n                  training_frame = train_hf, \\\n                  validation_frame = valid_hf, \\\n                  variable_importances=True)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### The best model is ...", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "models_grid.sort_by('auc', False)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### The best model details", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "best_model = h2o.get_model(models_grid.sort_by('auc', False)[0][0])\nbest_model.model_performance(valid_hf)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "### What are most important features?", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "best_model.varimp(use_pandas=True)", "outputs": [], "metadata": {"collapsed": false}}, {"source": "# Congratulations you built your first model using Azure + PySparkling and H2O!!!", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"name": "python"}}, "anaconda-cloud": {}}}
